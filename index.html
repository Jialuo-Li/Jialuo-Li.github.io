<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Jialuo Li | 李佳烙</title>

    <meta name="author" content="Jialuo Li">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/favicon/icon.ico" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    
  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Jialuo Li
                </p>
                <p>
                  I'm a junior undergraduate student majoring Computer Science and Technology at <a href="https://iiis.tsinghua.edu.cn/en/">IIIS</a>, 
                  <a href="https://www.tsinghua.edu.cn/en/">Tsinghua University</a> (a.k.a <a href="https://iiis.tsinghua.edu.cn/en/yaoclass/">Yao Class</a>, , directed by the Turing Award Laureate <a href="https://iiis.tsinghua.edu.cn/yao/">Andrew Chi-Chih Yao</a>). 
                  Currently I am a research intern at <a href="https://www.nyu.edu/">NYU</a> advised by Prof. <a href="https://www.sainingxie.com/">Saining Xie</a>. 
                  In addition, I am privileged to work closely with Prof. <a href="https://ericyi.github.io/">Li Yi</a>.
                </p>
                <p style="text-align:center">
                  <a href="lijialao21@mails.tsinghua.edu.cn">Email</a> &nbsp;/&nbsp;
                  <a href="data/CVJialuo.pdf">CV</a> &nbsp;/&nbsp;
                  <a href="https://scholar.google.com/citations?user=xl9hSggAAAAJ&hl=zh-CN">Google Scholar</a> &nbsp;/&nbsp;
                  <a href="https://x.com/JiaLuo_Li21">Twitter</a> &nbsp;/&nbsp;
                  <a href="https://github.com/Jialuo-Li">Github</a>
                </p>
              </td>
              <td style="padding:2.5%;width:40%;max-width:40%">
                <a href="images/Jialuo.jpg"><img style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%;" alt="profile photo" src="images/Jialuo.jpg" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody></table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <h2>Research</h2>
                <p>
                  I'm interested in computer vision, deep learning, generative AI, and image processing. Most of my research is about inferring the physical world (shape, motion, color, light, etc) from images, usually with radiance fields. Some papers are <span class="highlight">highlighted</span>.
                </p>
              </td>
            </tr>
          </tbody></table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <h2>News</h2>
                <p>
                  <li><strong>2024-07:</strong> ✨ Our paper <a href="https://arxiv.org/abs/2404.01343">CHOPS</a> was accepted by COLM 2024!</li>
                  <li><strong>2024-02:</strong> I will start my internship in NYU Courant advised by Prof. <a href="https://www.sainingxie.com/" target="_blank">Saining Xie</a>. Looking forward to working with Saining in New York!</li>
                  <li><strong>2024-01:</strong> ✨ Our graphics course project is now available! Feel free to explore and try it out <a href="https://github.com/ziyuyuyuyu1/ACG-Project">here</a>.</li>
                </p>
              </td>
            </tr>
          </tbody></table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            
            <h2>Publications</h2>

            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/CHOPS.png" alt="PontTuset" width="200" style="border-style: none">
              </td>
              <td width="75%" valign="middle">
                <a href="https://arxiv.org/abs/2404.01343">
                  <span class="papertitle"> CHOPS: CHat with custOmer Profile Systems for Customer Service with LLMs
                  </span>
                </a>
                <br>
                <a href="https://github.com/JingzheShi">Jingzhe Shi</a>, 
                <strong>Jialuo Li</strong>, 
                <a href="https://github.com/Aquahorse">Qinwei Ma</a>, 
                <a href="https://github.com/Faded-Nebula">Zaiwen Yang</a>, 
                <a href="https://github.com/cjxh21">Huan Ma</a>, 
                <a href="https://scholar.google.com/citations?user=DOyVxx0AAAAJ&">Lei Li</a>
                <br>
                <em>COLM 2024 </em>
                <br>
                <a href="https://github.com/JingzheShi/CHOPS">Project Page</a>
                /
                <a href="https://arxiv.org/abs/2404.01343">arXiv</a>
                <p></p>
                <p>We propose CHOPS, an LLM agent designed to efficiently access user information, interact with existing systems, and provide accurate, safe responses by leveraging a combination of small and large LLMs. Validated using the CPHOS-dataset, CHOPS demonstrates its potential to enhance or replace human customer service.</p>
              </td>
            </tr>

            <!-- <tr onmouseout="nuvo_stop()" onmouseover="nuvo_start()">
              <td style="padding:20px;width:25%;vertical-align:middle">
                <div class="one">
                  <div class="two" id='nuvo_image'><video  width=100% muted autoplay loop>
                  <source src="images/nuvo.mp4" type="video/mp4">
                  Your browser does not support the video tag.
                  </video></div>
                  <img src='images/nuvo.jpg' width=100%>
                </div>
                <script type="text/javascript">
                  function nuvo_start() {
                    document.getElementById('nuvo_image').style.opacity = "1";
                  }

                  function nuvo_stop() {
                    document.getElementById('nuvo_image').style.opacity = "0";
                  }
                  nuvo_stop()
                </script>
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <a href="https://pratulsrinivasan.github.io/nuvo/">
                  <span class="papertitle">Nuvo: Neural UV Mapping for Unruly 3D Representations</span>
                </a>
                <br>
                <a href="https://pratulsrinivasan.github.io/">Pratul Srinivasan</a>,
                <a href="http://stephangarbin.com/">Stephan J. Garbin</a>,
                <a href="https://dorverbin.github.io/">Dor Verbin</a>,
                <strong>Jonathan T. Barron</strong>,
                <a href="https://bmild.github.io/">Ben Mildenhall</a>
                <br>
                <em>ECCV</em>, 2024
                <br>
                <a href="https://pratulsrinivasan.github.io/nuvo/">project page</a>
                /
                <a href="https://www.youtube.com/watch?v=hmJiOSTDQZI">video</a>
                /
                <a href="http://arxiv.org/abs/2312.05283">arXiv</a>
                <p></p>
                <p>
                Neural fields let you recover editable UV mappings for the challenging geometries produced by NeRF-like models.
                </p>
              </td>
            </tr>


            <tr onmouseout="cat3d_stop()" onmouseover="cat3d_start()" bgcolor="#ffffd0">
              <td style="padding:20px;width:25%;vertical-align:middle">
                <div class="one">
                  <div class="two" id='cat3d_image'><video  width=100% height=100% muted autoplay loop>
                  <source src="images/cat3d.mp4" type="video/mp4">
                  Your browser does not support the video tag.
                  </video></div>
                  <img src='images/cat3d.jpg' width="160">
                </div>
                <script type="text/javascript">
                  function cat3d_start() {
                    document.getElementById('cat3d_image').style.opacity = "1";
                  }

                  function cat3d_stop() {
                    document.getElementById('cat3d_image').style.opacity = "0";
                  }
                  cat3d_stop()
                </script>
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <a href="https://cat3d.github.io/">
                <span class="papertitle">CAT3D: Create Anything in 3D with Multi-View Diffusion Models</span>
                </a>
                <br>
                <a href="https://ruiqigao.github.io/">Ruiqi Gao</a>*,
                <a href="https://holynski.org/">Aleksander Holynski</a>*, 
                <a href="https://henzler.github.io/">Philipp Henzler</a>,
                <a href="https://github.com/ArthurBrussee">Arthur Brussee</a>, 
                <a href="http://ricardomartinbrualla.com/">Ricardo Martin Brualla</a>, 
                <a href="https://pratulsrinivasan.github.io/">Pratul P. Srinivasan</a>,
                <strong>Jonathan T. Barron</strong>,
                <a href="https://poolio.github.io/">Ben Poole</a>*

                <br>
                <em>arXiv</em>, 2024
                <br>
                <a href="https://cat3d.github.io/">project page</a>
                /
                <a href="https://arxiv.org/abs/2405.10314">arXiv</a>
                <p></p>
                <p>
                A single model built around diffusion and NeRF that does text-to-3D, image-to-3D, and few-view reconstruction, trains in 1 minute, and renders at 60FPS in a browser.
                </p>
              </td>
            </tr> -->

          </tbody></table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            
            <h2>Projects</h2>

            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/acg_project.png" alt="PontTuset" width="200" style="border-style: none">
              </td>
              <td width="75%" valign="middle">
                <a href="https://ziyuyuyuyu1.github.io/ACG-UI/">
                  <span class="papertitle"> Generative 3D Mesh Modeling with Text-to-Texture Generator
                  </span>
                </a>
                <br>
                <strong>Jialuo Li</strong>*, 
                <a href="https://github.com/ziyuyuyuyu1">Ziru Huang</a>*
                <br>
                <a href="https://ziyuyuyuyu1.github.io/ACG-UI/">Project Page</a>
                /
                <a href="https://github.com/ziyuyuyuyu1/ACG-Project">Code</a>
                /
                <a href="/data/ACG_pre.pdf">Presentation</a>
                <p></p>
                <p>Our project extends <a href="https://arxiv.org/abs/2303.08133">MeshDiffusion</a> by incorporating class conditioning for 3D mesh generation and using a pre-trained 2D diffusion model to align textures with textual descriptions. Despite challenges in environment setup and data preprocessing, our method effectively generates and textures category-specific 3D meshes.</p>
              </td>
            </tr>
          </tbody></table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            
            <h2>Experience</h2>
            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle"><img src="images/nyu_logo.png", width="150"></td>
              <td width="75%" valign="center">
                <strong><a href="https://www.nyu.edu/" target="_blank"><span class="papertitle">New York University</span> </a></strong>
                <br> <em>2024.02 - Present</em><br>  <strong>Research Intern</strong>
                <br> Research Advisor: Prof. <a href="https://www.sainingxie.com/" target="_blank">Saining Xie</a>
              </td>
            </tr>

            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle"><img src="images/Tsinghua_logo.png", width="150"></td>
              <td width="75%" valign="center">
                <strong><a href="https://www.tsinghua.edu.cn/" target="_blank"><span class="papertitle">Tsinghua University</span> </a></strong>
                <br> <em>2021.09 - Present</em><br>  <strong>Undergraduate Student </strong>
              </td>
            </tr>
          
          </tbody></table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            
            <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <h2>Honors and Awards</h2>
                <p>
                  <li><strong>2023:</strong> Outstanding Scholarship in Social Work from Tsinghua University.</li>
                </p>
                <p>
                  <li><strong>2022:</strong> Mr. and Mrs. Wong Yi-Chung Award, Friends of Tsinghua University.</li>
                </p>
                <p>
                  <li><strong>2022:</strong> Outstanding Scholarship in Social Work from Tsinghua University.</li>
                </p>
                <p>
                  <li><strong>2021:</strong> Member of the Chinese team of the Asian Physics Olympiad (<a href="http://asianphysicsolympiad.org/">APhO</a>).</li>
                </p>
                <p>
                  <li><strong>2020:</strong> Gold Medalist 🏅 in the 37th Chinese Physics Olympiad (<a href="https://cpho.pku.edu.cn/info/1070/1207.htm">CPhO</a>), <strong>ranking tenth nationwide</strong>.</li>
                </p>
              </td>
            </tr>

          </tbody></table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:0px">
                <br>
                <p style="text-align:center;font-size:small;">
                  This homepage is designed based on <a href="http://jonbarron.info/">Jon Barron</a>'s homepage and deployed on <a href="https://pages.github.com/">GitHub Pages</a>. Last updated: Aug 06, 2024.
                  <br> © 2024 Jialuo Li
                </p>
              </td>
            </tr>
          </tbody></table>
        </td>
      </tr>
    </table>
  </body>
</html>
